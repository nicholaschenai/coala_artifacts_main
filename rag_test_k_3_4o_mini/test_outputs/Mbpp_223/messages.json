[
    {
        "role": "system",
        "content": "\nYou are an expert programmer tasked with solving the problem below.\n\nFollow the user's instructions to solve the problem.\nThe user can ask for analysis, code, or both.\n\n## Instructions\nWhen asked to output code,\n- Make sure to wrap your code in '```python' and '```' Markdown delimiters, \n- include exactly one block of code with the entire solution\n- No outside libraries are allowed. \n- Builtins are allowed.\n- If the task specifies a function name to be used, follow it strictly (be case sensitive!) and declare the that function last (helper functions are declared first).\n- DO NOT write any assert statements / tests.\n\n## Problem\n[BEGIN PROBLEM]\nWrite a Python function that satisfies the description below. Your code must strictly follow the function name and typings of the input and output specified in the assert statement below, and pass the assertion when executed.\n\"\"\"\nWrite a function that takes in a sorted array, its length (n), and an element and returns whether the element is the majority element in the given sorted array. (The majority element is the element that occurs more than n/2 times.)\nassert is_majority([1, 2, 3, 3, 3, 3, 10], 7, 3) == True\n\"\"\"\n\n[END PROBLEM]\n"
    },
    {
        "role": "user",
        "content": "\n## Instructions\n\nReason through the problem and:\n1. Restate the problem in plain English\n2. Conceptualize a solution first in plain English\n3. Write a pseudocode solution\n4. Output the final Python 3 solution with your solution steps in comments.\n\nMake sure to wrap your code in '```python' and '```' Markdown delimiters, \nand include exactly one block of code with the entire solution.\n\nNo outside libraries are allowed.\nBuiltins are allowed.\n"
    },
    {
        "role": "assistant",
        "content": "1. **Restate the problem in plain English:**\n   We need to create a function that checks if a given element in a sorted array appears more than half the time (n/2) in that array. If it does, we return `True`, indicating that it is the majority element; otherwise, we return `False`.\n\n2. **Conceptualize a solution first in plain English:**\n   - First, we need to determine how many times the specified element appears in the array.\n   - Since the array is sorted, we can find the first and last occurrence of the element using binary search.\n   - We can then calculate the count of the element by subtracting the index of the first occurrence from the index of the last occurrence and adding one.\n   - Finally, we compare this count to n/2 to determine if it is a majority element.\n\n3. **Write a pseudocode solution:**\n   ```\n   function is_majority(arr, n, element):\n       if n is 0:\n           return False\n       \n       first_index = find_first_index(arr, element)\n       if first_index is -1:\n           return False\n       \n       last_index = find_last_index(arr, element)\n       count = last_index - first_index + 1\n       \n       return count > n / 2\n\n   function find_first_index(arr, element):\n       // Implement binary search to find the first index of element\n\n   function find_last_index(arr, element):\n       // Implement binary search to find the last index of element\n   ```\n\n4. **Output the final Python 3 solution with your solution steps in comments:**\n```python\ndef find_first_index(arr, element):\n    left, right = 0, len(arr) - 1\n    first_index = -1\n    while left <= right:\n        mid = (left + right) // 2\n        if arr[mid] == element:\n            first_index = mid\n            right = mid - 1  # continue searching in the left half\n        elif arr[mid] < element:\n            left = mid + 1\n        else:\n            right = mid - 1\n    return first_index\n\ndef find_last_index(arr, element):\n    left, right = 0, len(arr) - 1\n    last_index = -1\n    while left <= right:\n        mid = (left + right) // 2\n        if arr[mid] == element:\n            last_index = mid\n            left = mid + 1  # continue searching in the right half\n        elif arr[mid] < element:\n            left = mid + 1\n        else:\n            right = mid - 1\n    return last_index\n\ndef is_majority(arr, n, element):\n    if n == 0:\n        return False\n    \n    first_index = find_first_index(arr, element)\n    if first_index == -1:\n        return False\n    \n    last_index = find_last_index(arr, element)\n    count = last_index - first_index + 1\n    \n    return count > n / 2\n```"
    },
    {
        "role": "user",
        "content": "\nAlso, here are some of your memories.\nFeel free to use the given information to aid your problem solving process if necessary.\nDo not confuse the memories with the problem statement.\n\n## Memories\n\n[Textbook Reference Material]:\n    Title: Binary search\n    Part: 1/2\n    # Binary search\n\n    **Binary search** is a method that allows for quicker search of something by splitting the search interval into two. Its most common application is searching values in sorted arrays, however the splitting idea is crucial in many other typical tasks.\n\n    ## Search in sorted arrays\n\n    The most typical problem that leads to the binary search is as follows. You're given a sorted array $A_0 \\leq A_1 \\leq \\dots \\leq A_{n-1}$, check if $k$ is present within the sequence. The simplest solution would be to check every element one by one and compare it with $k$ (a so-called linear search). This approach works in $O(n)$, but doesn't utilize the fact that the array is sorted.\n\n    <center>\n    <img src=\"https://upload.wikimedia.org/wikipedia/commons/8/83/Binary_Search_Depiction.svg\" width=\"800px\">\n    <br>\n    <i>Binary search of the value $7$ in an array</i>.\n    <br>\n    <i>The <a href=\"https://commons.wikimedia.org/wiki/File:Binary_Search_Depiction.svg\">image</a> by [AlwaysAngry](https://commons.wikimedia.org/wiki/User:AlwaysAngry) is distributed under <a href=\"https://creativecommons.org/licenses/by-sa/4.0/deed.en\">CC BY-SA 4.0</a></i> license.\n    </center>\n\n    Now assume that we know two indices $L < R$ such that $A_L \\leq k \\leq A_R$. Because the array is sorted, we can deduce that $k$ either occurs among $A_L, A_{L+1}, \\dots, A_R$ or doesn't occur in the array at all. If we pick an arbitrary index $M$ such that $L < M < R$ and check whether $k$ is less or greater than $A_M$. We have two possible cases:\n\n    1. $A_L \\leq k \\leq A_M$. In this case, we reduce the problem from $[L, R]$ to $[L, M]$;\n    1. $A_M \\leq k \\leq A_R$. In this case, we reduce the problem from $[L, R]$ to $[M, R]$.\n\n    When it is impossible to pick  $M$, that is, when $R = L + 1$, we directly compare $k$ with $A_L$ and $A_R$. Otherwise we would want to pick $M$ in such manner that it reduces the active segment to a single element as quickly as possible _in the worst case_.\n\n    Since in the worst case we will always reduce to larger segment of $[L, M]$ and $[M, R]$. Thus, in the worst case scenario the reduction would be from $R-L$ to $\\max(M-L, R-M)$. To minimize this value, we should pick $M \\approx \\frac{L+R}{2}$, then\n\n    $$\n    M-L \\approx \\frac{R-L}{2} \\approx R-M.\n    $$\n\n    In other words, from the worst-case scenario perspective it is optimal to always pick $M$ in the middle of $[L, R]$ and split it in half. Thus, the active segment halves on each step until it becomes of size $1$. So, if the process needs $h$ steps, in the end it reduces the difference between $R$ and $L$ from $R-L$ to $\\frac{R-L}{2^h} \\approx 1$, giving us the equation $2^h \\approx R-L$.\n\n    Taking $\\log_2$ on both sides, we get $h \\approx \\log_2(R-L) \\in O(\\log n)$.\n\n    Logarithmic number of steps is drastically better than that of linear search. For example, for $n \\approx 2^{20} \\approx 10^6$ you'd need to make approximately a million operations for linear search, but only around $20$ operations with the binary search.\n\n    ### Lower bound and upper bound\n\n    It is often convenient to find the position of the first element that is not less than $k$ (called the lower bound of $k$ in the array) or the position of the first element that is greater than $k$ (called the upper bound of $k$) rather than the exact position of the element.\n\n    Together, lower and upper bounds produce a possibly empty half-interval of the array elements that are equal to $k$. To check whether $k$ is present in the array it's enough to find its lower bound and check if the corresponding element equates to $k$.\n\n    ### Implementation\n\n    The explanation above provides a rough description of the algorithm. For the implementation details, we'd need to be more precise.\n\n    We will maintain a pair $L < R$ such that $A_L \\leq k < A_R$. Meaning that the active search interval is $[L, R)$. We use half-interval here instead of a segment $[L, R]$ as it turns out to require less corner case work.\n\n    When $R = L+1$, we can deduce from definitions above that $R$ is the upper bound of $k$. It is convenient to initialize $R$ with past-the-end index, that is $R=n$ and $L$ with before-the-beginning index, that is $L=-1$. It is fine as long as we never evaluate $A_L$ and $A_R$ in our algorithm directly, formally treating it as $A_L = -\\infty$ and $A_R = +\\infty$.\n\n    Finally, to be specific about the value of $M$ we pick, we will stick with $M = \\lfloor \\frac{L+R}{2} \\rfloor$.\n\n    Then the implementation could look like this:\n\n    ```cpp\n    ... // a sorted array is stored as a[0], a[1], ..., a[n-1]\n    int l = -1, r = n;\n    while(r - l > 1) {\n        int m = (l + r) / 2;\n        if(k < a[m]) {\n            r = m; // a[l] <= k < a[m] <= a[r]\n        } else {\n            l = m; // a[l] <= a[m] <= k < a[r]\n        }\n    }\n    ```\n\n    During the execution of the algorithm, we never evaluate neither $A_L$ nor $A_R$, as $L < M < R$. In the end, $L$ will be the index of the last element that is not greater than $k$ (or $-1$ if there is no such element) and $R$ will be the index of the first element larger than $k$ (or $n$ if there is no such element).\n\n    ## Search on arbitrary predicate\n\n    Let $f : \\{0,1,\\dots, n-1\\} \\to \\{0, 1\\}$ be a boolean function defined on $0,1,\\dots,n-1$ such that it is monotonous, that is\n\n    $$\n    f(0) \\leq f(1) \\leq \\dots \\leq f(n-1).\n    $$\n\n    The binary search, the way it is described above, finds the partition of the array by the predicate $f(M)$, holding the boolean value of $k < A_M$ expression. In other words, binary search finds the unique index $L$ such that $f(L) = 0$ and $f(R)=f(L+1)=1$.\n\n    It is possible to use arbitrary monotonous predicate instead of $k < A_M$. It is particularly useful when the computation of $f(k)$ is requires too much time to actually compute it for every possible value.\n\n    ```cpp\n    ... // f(i) is a boolean function such that f(0) <= ... <= f(n-1)\n    int l = -1, r = n;\n    while(r - l > 1) {\n        int m = (l + r) / 2;\n        if(f(m)) {\n            r = m; // 0 = f(l) < f(m) = 1\n        } else {\n            l = m; // 0 = f(m) < f(r) = 1\n        }\n    }\n[/Textbook Reference Material]\n\n\n[Textbook Reference Material]:\n    Chapter: Sorting\n    Section: Binary search\n    Part: 1/1\n    \\section{Binary search}\n\n    \\index{binary search}\n\n    A general method for searching for an element\n    in an array is to use a \\texttt{for} loop\n    that iterates through the elements of the array.\n    For example, the following code searches for\n    an element $x$ in an array:\n\n    \\begin{lstlisting}\n    for (int i = 0; i < n; i++) {\n        if (array[i] == x) {\n            // x found at index i\n        }\n    }\n    \\end{lstlisting}\n\n    The time complexity of this approach is $O(n)$,\n    because in the worst case, it is necessary to check\n    all elements of the array.\n    If the order of the elements is arbitrary,\n    this is also the best possible approach, because\n    there is no additional information available where\n    in the array we should search for the element $x$.\n\n    However, if the array is \\emph{sorted},\n    the situation is different.\n    In this case it is possible to perform the\n    search much faster, because the order of the\n    elements in the array guides the search.\n    The following \\key{binary search} algorithm\n    efficiently searches for an element in a sorted array\n    in $O(\\log n)$ time.\n\n    \\subsubsection{Method 1}\n\n    The usual way to implement binary search\n    resembles looking for a word in a dictionary.\n    The search maintains an active region in the array,\n    which initially contains all array elements.\n    Then, a number of steps is performed,\n    each of which halves the size of the region.\n\n    At each step, the search checks the middle element\n    of the active region.\n    If the middle element is the target element,\n    the search terminates.\n    Otherwise, the search recursively continues\n    to the left or right half of the region,\n    depending on the value of the middle element.\n\n    The above idea can be implemented as follows:\n    \\begin{lstlisting}\n    int a = 0, b = n-1;\n    while (a <= b) {\n        int k = (a+b)/2;\n        if (array[k] == x) {\n            // x found at index k\n        }\n        if (array[k] > x) b = k-1;\n        else a = k+1;\n    }\n    \\end{lstlisting}\n\n    In this implementation, the active region is $a \\ldots b$,\n    and initially the region is $0 \\ldots n-1$.\n    The algorithm halves the size of the region at each step,\n    so the time complexity is $O(\\log n)$.\n\n    \\subsubsection{Method 2}\n\n    An alternative method to implement binary search\n    is based on an efficient way to iterate through\n    the elements of the array.\n    The idea is to make jumps and slow the speed\n    when we get closer to the target element.\n\n    The search goes through the array from left to\n    right, and the initial jump length is $n/2$.\n    At each step, the jump length will be halved:\n    first $n/4$, then $n/8$, $n/16$, etc., until\n    finally the length is 1.\n    After the jumps, either the target element has\n    been found or we know that it does not appear in the array.\n\n    The following code implements the above idea:\n    \\begin{lstlisting}\n    int k = 0;\n    for (int b = n/2; b >= 1; b /= 2) {\n        while (k+b < n && array[k+b] <= x) k += b;\n    }\n    if (array[k] == x) {\n        // x found at index k\n    }\n    \\end{lstlisting}\n\n    During the search, the variable $b$\n    contains the current jump length.\n    The time complexity of the algorithm is $O(\\log n)$,\n    because the code in the \\texttt{while} loop\n    is performed at most twice for each jump length.\n\n    \\subsubsection{C++ functions}\n\n    The C++ standard library contains the following functions\n    that are based on binary search and work in logarithmic time:\n\n    \\begin{itemize}\n    \\item \\texttt{lower\\_bound} returns a pointer to the\n    first array element whose value is at least $x$.\n    \\item \\texttt{upper\\_bound} returns a pointer to the\n    first array element whose value is larger than $x$.\n    \\item \\texttt{equal\\_range} returns both above pointers.\n    \\end{itemize}\n\n    The functions assume that the array is sorted.\n    If there is no such element, the pointer points to\n    the element after the last array element.\n    For example, the following code finds out whether\n    an array contains an element with value $x$:\n\n    \\begin{lstlisting}\n    auto k = lower_bound(array,array+n,x)-array;\n    if (k < n && array[k] == x) {\n        // x found at index k\n    }\n    \\end{lstlisting}\n\n    Then, the following code counts the number of elements\n    whose value is $x$:\n\n    \\begin{lstlisting}\n    auto a = lower_bound(array, array+n, x);\n    auto b = upper_bound(array, array+n, x);\n    cout << b-a << \"\\n\";\n    \\end{lstlisting}\n\n    Using \\texttt{equal\\_range}, the code becomes shorter:\n\n    \\begin{lstlisting}\n    auto r = equal_range(array, array+n, x);\n    cout << r.second-r.first << \"\\n\";\n    \\end{lstlisting}\n\n    \\subsubsection{Finding the smallest solution}\n\n    An important use for binary search is\n    to find the position where the value of a \\emph{function} changes.\n    Suppose that we wish to find the smallest value $k$\n    that is a valid solution for a problem.\n    We are given a function $\\texttt{ok}(x)$\n    that returns \\texttt{true} if $x$ is a valid solution\n    and \\texttt{false} otherwise.\n    In addition, we know that $\\texttt{ok}(x)$ is \\texttt{false}\n    when $x<k$ and \\texttt{true} when $x \\ge k$.\n    The situation looks as follows:\n\n    \\begin{center}\n    \\begin{tabular}{r|rrrrrrrr}\n    $x$ & 0 & 1 & $\\cdots$ & $k-1$ & $k$ & $k+1$ & $\\cdots$ \\\\\n    \\hline\n    $\\texttt{ok}(x)$ & \\texttt{false} & \\texttt{false}\n    & $\\cdots$ & \\texttt{false} & \\texttt{true} & \\texttt{true} & $\\cdots$ \\\\\n    \\end{tabular}\n    \\end{center}\n\n    \\noindent\n    Now, the value of $k$ can be found using binary search:\n\n    \\begin{lstlisting}\n    int x = -1;\n    for (int b = z; b >= 1; b /= 2) {\n        while (!ok(x+b)) x += b;\n    }\n    int k = x+1;\n    \\end{lstlisting}\n\n    The search finds the largest value of $x$ for which\n    $\\texttt{ok}(x)$ is \\texttt{false}.\n    Thus, the next value $k=x+1$\n    is the smallest possible value for which\n    $\\texttt{ok}(k)$ is \\texttt{true}.\n    The initial jump length $z$ has to be\n    large enough, for example some value\n    for which we know beforehand that $\\texttt{ok}(z)$ is \\texttt{true}.\n\n    The algorithm calls the function \\texttt{ok}\n    $O(\\log z)$ times, so the total time complexity\n    depends on the function \\texttt{ok}.\n    For example, if the function works in $O(n)$ time,\n    the total time complexity is $O(n \\log z)$.\n\n    \\subsubsection{Finding the maximum value}\n\n    Binary search can also be used to find\n    the maximum value for a function that is\n    first increasing and then decreasing.\n    Our task is to find a position $k$ such that\n\n    \\begin{itemize}\n    \\item\n    $f(x)<f(x+1)$ when $x<k$, and\n    \\item\n    $f(x)>f(x+1)$ when $x \\ge k$.\n    \\end{itemize}\n\n    The idea is to use binary search\n    for finding the largest value of $x$\n    for which $f(x)<f(x+1)$.\n    This implies that $k=x+1$\n    because $f(x+1)>f(x+2)$.\n    The following code implements the search: \n\n    \\begin{lstlisting}\n    int x = -1;\n    for (int b = z; b >= 1; b /= 2) {\n        while (f(x+b) < f(x+b+1)) x += b;\n    }\n    int k = x+1;\n    \\end{lstlisting}\n\n    Note that unlike in the ordinary binary search,\n    here it is not allowed that consecutive values\n    of the function are equal.\n    In this case it would not be possible to know\n    how to continue the search.\n[/Textbook Reference Material]\n\n\n[Textbook Reference Material]:\n    Chapter: Data structures\n    Section: Comparison to sorting\n    Part: 1/1\n    \\section{Comparison to sorting}\n\n    It is often possible to solve a problem\n    using either data structures or sorting.\n    Sometimes there are remarkable differences\n    in the actual efficiency of these approaches,\n    which may be hidden in their time complexities.\n\n    Let us consider a problem where\n    we are given two lists $A$ and $B$\n    that both contain $n$ elements.\n    Our task is to calculate the number of elements\n    that belong to both of the lists.\n    For example, for the lists\n    \\[A = [5,2,8,9] \\hspace{10px} \\textrm{and} \\hspace{10px} B = [3,2,9,5],\\]\n    the answer is 3 because the numbers 2, 5\n    and 9 belong to both of the lists.\n\n    A straightforward solution to the problem is\n    to go through all pairs of elements in $O(n^2)$ time,\n    but next we will focus on\n    more efficient algorithms.\n\n    \\subsubsection{Algorithm 1}\n\n    We construct a set of the elements that appear in $A$,\n    and after this, we iterate through the elements\n    of $B$ and check for each elements if it\n    also belongs to $A$.\n    This is efficient because the elements of $A$\n    are in a set.\n    Using the \\texttt{set} structure,\n    the time complexity of the algorithm is $O(n \\log n)$.\n\n    \\subsubsection{Algorithm 2}\n\n    It is not necessary to maintain an ordered set,\n    so instead of the \\texttt{set} structure\n    we can also use the \\texttt{unordered\\_set} structure.\n    This is an easy way to make the algorithm\n    more efficient, because we only have to change\n    the underlying data structure.\n    The time complexity of the new algorithm is $O(n)$.\n\n    \\subsubsection{Algorithm 3}\n\n    Instead of data structures, we can use sorting.\n    First, we sort both lists $A$ and $B$.\n    After this, we iterate through both the lists\n    at the same time and find the common elements.\n    The time complexity of sorting is $O(n \\log n)$,\n    and the rest of the algorithm works in $O(n)$ time,\n    so the total time complexity is $O(n \\log n)$.\n\n    \\subsubsection{Efficiency comparison}\n\n    The following table shows how efficient\n    the above algorithms are when $n$ varies and\n    the elements of the lists are random\n    integers between $1 \\ldots 10^9$:\n\n    \\begin{center}\n    \\begin{tabular}{rrrr}\n    $n$ & Algorithm 1 & Algorithm 2 & Algorithm 3 \\\\\n    \\hline\n    $10^6$ & $1.5$ s & $0.3$ s & $0.2$ s \\\\\n    $2 \\cdot 10^6$ & $3.7$ s & $0.8$ s & $0.3$ s \\\\\n    $3 \\cdot 10^6$ & $5.7$ s & $1.3$ s & $0.5$ s \\\\\n    $4 \\cdot 10^6$ & $7.7$ s & $1.7$ s & $0.7$ s \\\\\n    $5 \\cdot 10^6$ & $10.0$ s & $2.3$ s & $0.9$ s \\\\\n    \\end{tabular}\n    \\end{center}\n\n    Algorithms 1 and 2 are equal except that\n    they use different set structures.\n    In this problem, this choice has an important effect on\n    the running time, because Algorithm 2\n    is 4\u20135 times faster than Algorithm 1.\n\n    However, the most efficient algorithm is Algorithm 3\n    which uses sorting.\n    It only uses half the time compared to Algorithm 2.\n    Interestingly, the time complexity of both\n    Algorithm 1 and Algorithm 3 is $O(n \\log n)$,\n    but despite this, Algorithm 3 is ten times faster.\n    This can be explained by the fact that\n    sorting is a simple procedure and it is done\n    only once at the beginning of Algorithm 3,\n    and the rest of the algorithm works in linear time.\n    On the other hand,\n    Algorithm 1 maintains a complex balanced binary tree\n    during the whole algorithm.\n[/Textbook Reference Material]\n\n"
    },
    {
        "role": "assistant",
        "content": "1. **Restate the problem in plain English**: \n   We need to create a function that checks if a given element appears more than half the time in a sorted array. This element is referred to as the \"majority element.\" If it does, the function should return `True`; otherwise, it should return `False`.\n\n2. **Conceptualize a solution first in plain English**: \n   Since the array is sorted, we can efficiently find the first and last occurrence of the element in question. If the count of this element (which can be calculated as the difference between the indices of its last and first occurrence) exceeds half the length of the array, we can conclude that it is the majority element.\n\n3. **Write a pseudocode solution**:\n   ```\n   function is_majority(arr, n, element):\n       if n == 0:\n           return False\n       \n       first_index = find_first_index(arr, element)\n       if first_index == -1:\n           return False\n       \n       last_index = find_last_index(arr, element)\n       count = last_index - first_index + 1\n       \n       return count > n / 2\n\n   function find_first_index(arr, element):\n       // Implement binary search to find the first occurrence of element\n\n   function find_last_index(arr, element):\n       // Implement binary search to find the last occurrence of element\n   ```\n\n4. **Output the final Python 3 solution with your solution steps in comments**:\n```python\ndef find_first_index(arr, element):\n    left, right = 0, len(arr)\n    while left < right:\n        mid = (left + right) // 2\n        if arr[mid] < element:\n            left = mid + 1\n        else:\n            right = mid\n    return left if left < len(arr) and arr[left] == element else -1\n\ndef find_last_index(arr, element):\n    left, right = 0, len(arr)\n    while left < right:\n        mid = (left + right) // 2\n        if arr[mid] <= element:\n            left = mid + 1\n        else:\n            right = mid\n    return left - 1 if left > 0 and arr[left - 1] == element else -1\n\ndef is_majority(arr, n, element):\n    # Check if the array is empty\n    if n == 0:\n        return False\n    \n    # Find the first index of the element\n    first_index = find_first_index(arr, element)\n    # If the element is not found, return False\n    if first_index == -1:\n        return False\n    \n    # Find the last index of the element\n    last_index = find_last_index(arr, element)\n    # Calculate the count of the element\n    count = last_index - first_index + 1\n    \n    # Check if the count is greater than n/2\n    return count > n / 2\n```"
    },
    {
        "role": "user",
        "content": "\n[Environment Feedback]:\n    Note: Tests are automatically generated and can be wrong.\n\n    Tests passed:\n    assert is_majority([1, 2, 3, 3, 3, 3, 10], 7, 3) == True\n\n    Tests failed:\n    None\n[/Environment Feedback]\n"
    }
]